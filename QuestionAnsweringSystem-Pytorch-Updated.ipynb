{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Similarity Model (QSM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S-Bert Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model\n",
    "%%run -i /Users/yqinamz/Desktop/QA_BOT/CS-QASystem-Torch/src/CS-QASystem-Torch/src/cs_qa_system_torch/train_QSM_Sbert.py \\\n",
    "--pretrain_model_path '/home/yqinamz/output/quora_sts-bert-base-nli-mean-tokens-2020-08-17_20-53-14/' \\\n",
    "--model_name '/home/yqinamz/output/Sbert_test' \\\n",
    "--train_data_path '/home/yqinamz/QA_Bot/QA_EXP/EXP_1002/Mix_2USE_8R_1009/' \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on Question-Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run -i /Users/yqinamz/Desktop/QA_BOT/CS-QASystem-Torch/src/CS-QASystem-Torch/src/cs_qa_system_torch/QSM_inference.py \\\n",
    "--saved_model_path '/home/yqinamz/output/quora_sts-bert-base-nli-mean-tokens-2020-08-17_20-53-14/' \\\n",
    "--test_data_path '/home/yqinamz/QA_Bot/QA_EXP/EXP_1002/Mix_2USE_8R_1009/test_sample.tsv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-Time Prediction for QSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "sys.path.append('/home/srikamma/efs/workspace/CS-QASystem-Torch/src/CS-QASystem-Torch/src/cs_qa_system_torch/')\n",
    "from question_similarity.qsm_inference import ScoringService as qsm_sp\n",
    "question = 'how to cancel my order'\n",
    "data = {'query':question}\n",
    "qsm_sp.predict(json.dumps(data))[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Retrieval (IR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training IR Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training BiEncoder model with BCE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_QASYSTEM_PACKAGE = '/home/srikamma/efs/workspace/CS-QASystem-Torch/src/CS-QASystem-Torch/'\n",
    "ROOT_QASYSTEM_DATA = '/data/QAData/'\n",
    "ROOT_QASYSTEM_ARTIFACTS = '/data/QAArtifacts/'\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(ROOT_QASYSTEM_PACKAGE,'src/cs_qa_system_torch/'))\n",
    "\n",
    "\n",
    "python_file = os.path.join(ROOT_QASYSTEM_PACKAGE,'src/cs_qa_system_torch/information_retrieval/ir_train.py')\n",
    "\n",
    "%run -i  $python_file \\\n",
    "        --train_data_path  {ROOT_QASYSTEM_DATA+'InformationRetrievalData/amazon/sample/train.tsv'} \\\n",
    "        --test_data_path {ROOT_QASYSTEM_DATA+'InformationRetrievalData/amazon/sample/test.tsv'} \\\n",
    "        --model_name_or_path 'bert-base-uncased' \\\n",
    "        --architecture 'bi' \\\n",
    "        --loss 'BiEncoderBCE' \\\n",
    "        --max_query_length 32 \\\n",
    "        --max_passage_length 384 \\\n",
    "        --do_lower_case \\\n",
    "        --train_batch_size 64 \\\n",
    "        --test_batch_size 128 \\\n",
    "        --num_train_epochs 2 \\\n",
    "        --gpu 0,1,2,3 \\\n",
    "        --save_steps 1000 \\\n",
    "        --print_freq 500 \\\n",
    "        --output_dir {ROOT_QASYSTEM_ARTIFACTS+'ir_artifacts/biencoder_bertbase/'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training BiEncoder with Weighted Softmax Loss(with Inbatch Negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## THIS CELL IS USED TO CREATE TRAINING FILE#################\n",
    "## This training using a json file with query, positive doc and list of hardnegative documents for each query\n",
    "\n",
    "import json\n",
    "def process_datapoint(datapoint, data, max_hard_negs, ignore_negatives=False):\n",
    "    QID = 'qid'\n",
    "    PID = 'pid'\n",
    "    PASSAGE = 'passage'\n",
    "    QUERY = 'query'\n",
    "    LABEL = 'label'\n",
    "    HARD_NEGATIVES = 'hard_negatives'\n",
    "    if datapoint[QID] in data:\n",
    "        val = data[datapoint[QID]]\n",
    "    else:\n",
    "        val = dict()\n",
    "        val[QUERY] = datapoint[QUERY]\n",
    "        val[PASSAGE] = []\n",
    "        val[HARD_NEGATIVES] = []\n",
    "        \n",
    "    if int(datapoint[LABEL]) == 1:\n",
    "        val[PASSAGE].append(datapoint[PASSAGE])\n",
    "    elif (int(datapoint[LABEL]) == 0) and (not ignore_negatives) and len(val[HARD_NEGATIVES]) < max_hard_negs:\n",
    "        val[HARD_NEGATIVES].append(datapoint[PASSAGE])    \n",
    "    data[datapoint[QID]] = val\n",
    "                \n",
    "\n",
    "def get_biencoder_data_amazon(input_file, output_file, max_hard_negs = 15):\n",
    "    data = dict()\n",
    "    with open(input_file,'r') as f:\n",
    "        header = f.readline().strip().split('\\t')\n",
    "        count = 0\n",
    "        for line in f:\n",
    "            count += 1\n",
    "            dataline = line.strip().split('\\t')\n",
    "            datapoint = dict()\n",
    "            for index,title in enumerate(header):\n",
    "                datapoint[title] = dataline[index]\n",
    "            process_datapoint(datapoint, data, max_hard_negs = max_hard_negs)\n",
    "\n",
    "    keys_to_del = []\n",
    "    for key in data:\n",
    "        if len(data[key]['passage']) == 0:\n",
    "            keys_to_del.append(key)\n",
    "\n",
    "    for key in keys_to_del:\n",
    "        del data[key]\n",
    "\n",
    "    data['701375']['hard_negatives'] = ['i\\'m testing with this', 'thid hjh']\n",
    "    with open(output_file, \"w\") as outfile:  \n",
    "        json.dump(data, outfile)\n",
    "        \n",
    "    return data\n",
    "\n",
    "input_file = ROOT_QASYSTEM_DATA+'InformationRetrievalData/amazon/sample/train1.tsv'\n",
    "output_file = ROOT_QASYSTEM_DATA+'InformationRetrievalData/amazon/sample/train_datapoints.json'\n",
    "#input_file = '/data/qyouran/QABot/d2_benchmark/final_data_bi/train.tsv'\n",
    "#output_file = '/data/QAData/InformationRetrievalData/amazon/sample/train_datapoints.json'\n",
    "data = get_biencoder_data(input_file, output_file, max_hard_negs = 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ROOT_QASYSTEM_PACKAGE = '/home/srikamma/efs/workspace/CS-QASystem-Torch/src/CS-QASystem-Torch/'\n",
    "ROOT_QASYSTEM_DATA = '/data/QAData/'\n",
    "ROOT_QASYSTEM_ARTIFACTS = '/data/QAArtifacts/'\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(ROOT_QASYSTEM_PACKAGE,'src/cs_qa_system_torch/'))\n",
    "\n",
    "python_file = os.path.join(ROOT_QASYSTEM_PACKAGE,'src/cs_qa_system_torch/information_retrieval/ir_train.py')\n",
    "\n",
    "%run -i  $python_file \\\n",
    "        --train_data_path  {ROOT_QASYSTEM_DATA+'InformationRetrievalData/amazon/sample/train_datapoints.json'} \\\n",
    "        --test_data_path {ROOT_QASYSTEM_DATA+'InformationRetrievalData/amazon/sample/test.tsv'} \\\n",
    "        --model_name_or_path 'bert-base-uncased' \\\n",
    "        --architecture 'bi' \\\n",
    "        --loss 'BiEncoderNLL' \\\n",
    "        --max_query_length 32 \\\n",
    "        --max_passage_length 384 \\\n",
    "        --use_hard_negatives \\\n",
    "        --hard_negatives_weight_factor 0.65\\\n",
    "        --projection_dim 128 \\\n",
    "        --do_lower_case \\\n",
    "        --train_batch_size 8 \\\n",
    "        --test_batch_size 128 \\\n",
    "        --num_train_epochs 2 \\\n",
    "        --gpu 1 \\\n",
    "        --save_steps 1000 \\\n",
    "        --print_freq 500 \\\n",
    "        --output_dir {ROOT_QASYSTEM_ARTIFACTS+'ir_artifacts/biencoder_bertbase_hardneg'}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Bi-Encoder with Adding new Architecture for model, dataset & loss function (here Biencoder model with MSMARCO Dataset & Triplet loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "## For Training, the \"architecture\" parameter will result in different configuration of architectures, loss function and datasets.\n",
    "## If adding a new architecture,\n",
    "##       (a) In ir_utils.py update \"get_ir_model_attributes\" to return the model, config & tokenizer for both query and document\n",
    "##           for the new architecture. \n",
    "##           - It supports 'cross', 'bi' & 'single' as substring in the name of the architecture\n",
    "##           - If 'cross' in architecture the model has one encoder which takes both query and document together to compute the score\n",
    "##           - If 'bi' in architecture the model takes one encoder for query and another enocoder for document, computes embeddings and uses distance to compute score\n",
    "##           - If 'single' in architecture this is similar to 'bi' but it uses the same encoder for encoding both query and document\n",
    "##       (b) If the architecture does not fit into any of the current \"bi\", \"cross\", \"single\" encoder classes defined in \"ir_model.py\"\n",
    "##           create a new encoder model class for that architecture. \n",
    "##       (c) Make sure the model Instance you use for encoder is defined in \"get_encoding_vector\" function inside \"ir_model.py\". Update that \n",
    "##           function to allow the new model instance\n",
    "##       (c) Make sure correct query_transform and context_transform are instantiated in \"get_ir_data_transform\" function in \"ir_utils.py\" file\n",
    "##       (d) Make sure correct train_dataset, val_dataset are created for the given architecture in ir_train.py file\n",
    "##       (e) Make sure the correct loss function is passed as input argument --loss argument based on corresponding \n",
    "##           model architecture result in \"ir_model.py\" file and corresponding input passed to loss functions defined in \"ir_loss.py\" file\n",
    "\n",
    "\n",
    "## NOTE: model_name_or_path COULD BE A LOCAL PATH OR CHECKPOINT DIRECTORY WHERE THE MODEL WILL START FINETINING FROM THAT POINT\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/srikamma/efs/workspace/CS-QASystem-Torch/src/CS-QASystem-Torch/src/cs_qa_system_torch/')\n",
    "\n",
    "ROOT_QASYSTEM_PACKAGE = '/home/srikamma/efs/workspace/CS-QASystem-Torch/src/CS-QASystem-Torch/'\n",
    "ROOT_QASYSTEM_DATA = '/data/QAData/'\n",
    "ROOT_QASYSTEM_ARTIFACTS = '/data/QAArtifacts/'\n",
    "\n",
    "python_file = os.path.join(ROOT_QASYSTEM_PACKAGE,'src/cs_qa_system_torch/information_retrieval/ir_train.py')\n",
    "\n",
    "%run -i  $python_file \\\n",
    "        --train_data_path  {ROOT_QASYSTEM_DATA+'MSMARCO/trainsample.tsv'} \\\n",
    "        --test_data_path {ROOT_QASYSTEM_DATA+'MSMARCO/trainsample.tsv'} \\\n",
    "        --model_name_or_path 'bert-base-uncased' \\\n",
    "        --architecture 'bi-msmarco-triplet' \\\n",
    "        --loss 'BiEncoderNLL' \\\n",
    "        --max_query_length 32 \\\n",
    "        --max_passage_length 384 \\\n",
    "        --use_hard_negatives \\\n",
    "        --hard_negatives_weight_factor 0.0\\\n",
    "        --do_lower_case \\\n",
    "        --train_batch_size 40 \\\n",
    "        --test_batch_size 1024 \\\n",
    "        --num_train_epochs 2 \\\n",
    "        --gpu 0,1,2,3 \\\n",
    "        --save_steps 500 \\\n",
    "        --print_freq 25 \\\n",
    "        --output_dir {ROOT_QASYSTEM_ARTIFACTS+'ir_artifacts/msmarco_biencoder_triplet'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Cross Encoder with BCE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ROOT_QASYSTEM_PACKAGE = '/home/srikamma/efs/workspace/CS-QASystem-Torch/src/CS-QASystem-Torch/'\n",
    "ROOT_QASYSTEM_DATA = '/data/QAData/'\n",
    "ROOT_QASYSTEM_ARTIFACTS = '/data/QAArtifacts/'\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(ROOT_QASYSTEM_PACKAGE,'src/cs_qa_system_torch/'))\n",
    "\n",
    "\n",
    "python_file = os.path.join(ROOT_QASYSTEM_PACKAGE,'src/cs_qa_system_torch/information_retrieval/ir_train.py')\n",
    "\n",
    "%run -i  $python_file \\\n",
    "        --train_data_path  {ROOT_QASYSTEM_DATA+'InformationRetrievalData/amazon/sample/train.tsv'} \\\n",
    "        --test_data_path {ROOT_QASYSTEM_DATA+'InformationRetrievalData/amazon/sample/test.tsv'} \\\n",
    "        --model_name_or_path '/data/QAArtifacts/model/ir_artifacts/rerank_crossencoder_bert/' \\\n",
    "        --architecture 'cross' \\\n",
    "        --loss 'BCE' \\\n",
    "        --do_lower_case \\\n",
    "        --train_batch_size 32 \\\n",
    "        --test_batch_size 128 \\\n",
    "        --num_train_epochs 2 \\\n",
    "        --gpu 1,2 \\\n",
    "        --save_steps 1000 \\\n",
    "        --print_freq 500 \\\n",
    "        --output_dir {ROOT_QASYSTEM_ARTIFACTS+'ir_artifacts/crossencoder_bertbase/'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference IR Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ROOT_QASYSTEM_PACKAGE = '/home/srikamma/efs/workspace/CS-QASystem-Torch/src/CS-QASystem-Torch/'\n",
    "ROOT_QASYSTEM_DATA = '/data/QAData/'\n",
    "ROOT_QASYSTEM_ARTIFACTS = '/data/QAArtifacts/'\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(ROOT_QASYSTEM_PACKAGE,'src/cs_qa_system_torch/'))\n",
    "\n",
    "python_file = os.path.join(ROOT_QASYSTEM_PACKAGE,'src/cs_qa_system_torch/information_retrieval/ir_inference.py')\n",
    "\n",
    "%run -i  $python_file \\\n",
    "        --passage_collection_path {ROOT_QASYSTEM_DATA+'InformationRetrievalData/amazon/finetune_passage_collection.json'} \\\n",
    "        --qrels_path {ROOT_QASYSTEM_DATA+'InformationRetrievalData/amazon/finetune_qrels_rank_test.json'} \\\n",
    "        --rank_model_name_or_path 'BM25Okapi' \\\n",
    "        --rank_top_n 20 \\\n",
    "        --output_dir {ROOT_QASYSTEM_ARTIFACTS+'ir_artifacts/BM25_inference/'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference BiEncoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# CREATING DEV DATASET FOR MSMARCO USING BELOW CODE #######################\n",
    "\n",
    "### This requires creation of collection & qrels json file ########\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/srikamma/efs/workspace/CS-QASystem-Torch/src/CS-QASystem-Torch/src/cs_qa_system_torch/')\n",
    "\n",
    "from information_retrieval.ir_dataset import MSMARCOTripletDataset\n",
    "\n",
    "collection_filepath = '/data/QAData/MSMARCO/collection.tsv'\n",
    "queries_filepath = '/data/QAData/MSMARCO/queries.dev.tsv'\n",
    "triplet_filepath = '/data/QAData/MSMARCO/qrels.dev.small.tsv'\n",
    "\n",
    "MSMARCOTripletDataset.msmarco_create_dev_data_from_qrels(collection_filepath, queries_filepath, triplet_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/srikamma/efs/workspace/CS-QASystem-Torch/src/CS-QASystem-Torch/src/cs_qa_system_torch/')\n",
    "\n",
    "ROOT_QASYSTEM_PACKAGE = '/home/srikamma/efs/workspace/CS-QASystem-Torch/src/CS-QASystem-Torch/'\n",
    "ROOT_QASYSTEM_DATA = '/data/QAData/'\n",
    "ROOT_QASYSTEM_ARTIFACTS = '/data/QAArtifacts/'\n",
    "\n",
    "python_file = os.path.join(ROOT_QASYSTEM_PACKAGE,'src/cs_qa_system_torch/information_retrieval/ir_inference.py')\n",
    "\n",
    "%run -i  $python_file \\\n",
    "        --passage_collection_path {ROOT_QASYSTEM_DATA + 'MSMARCO/dev-collection.json'} \\\n",
    "        --qrels_path {ROOT_QASYSTEM_DATA + 'MSMARCO/dev-qrels.json'} \\\n",
    "        --rank_model_name_or_path {ROOT_QASYSTEM_ARTIFACTS+'ir_artifacts/msmarco_biencoder_triplet'} \\\n",
    "        --rank_batch_size 2048 \\\n",
    "        --rank_top_n 10 \\\n",
    "        --gpu 0,1,2,3 \\\n",
    "        --prediction_file 'prediction.tsv' \\\n",
    "        --overwrite_context_embeddings \\\n",
    "        --output_dir {ROOT_QASYSTEM_ARTIFACTS+'ir_artifacts/msmarco_biencoder_triplet_inference/'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference CrossEncoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ROOT_QASYSTEM_PACKAGE = '/home/srikamma/efs/workspace/CS-QASystem-Torch/src/CS-QASystem-Torch/'\n",
    "ROOT_QASYSTEM_DATA = '/data/QAData/'\n",
    "ROOT_QASYSTEM_ARTIFACTS = '/data/QAArtifacts/'\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(ROOT_QASYSTEM_PACKAGE,'src/cs_qa_system_torch/'))\n",
    "\n",
    "python_file = os.path.join(ROOT_QASYSTEM_PACKAGE,'src/cs_qa_system_torch/information_retrieval/ir_inference.py')\n",
    "\n",
    "%run -i  $python_file \\\n",
    "        --passage_collection_path {ROOT_QASYSTEM_DATA+'InformationRetrievalData/amazon/finetune_passage_collection.json'} \\\n",
    "        --qrels_path {ROOT_QASYSTEM_DATA+'InformationRetrievalData/amazon/finetune_qrels_rank_test.json'} \\\n",
    "        --rank_model_name_or_path {ROOT_QASYSTEM_ARTIFACTS+'ir_artifacts/crossencoder_bertbase/'} \\\n",
    "        --rank_batch_size 256 \\\n",
    "        --rank_top_n 20 \\\n",
    "        --gpu 0,1 \\\n",
    "        --output_dir {ROOT_QASYSTEM_ARTIFACTS+'ir_artifacts/crossencoder_bertbase_inference/'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference (BM25 + BiEncoder) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ROOT_QASYSTEM_PACKAGE = '/home/srikamma/efs/workspace/CS-QASystem-Torch/src/CS-QASystem-Torch/'\n",
    "ROOT_QASYSTEM_DATA = '/data/QAData/'\n",
    "ROOT_QASYSTEM_ARTIFACTS = '/data/QAArtifacts/'\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(ROOT_QASYSTEM_PACKAGE,'src/cs_qa_system_torch/'))\n",
    "\n",
    "python_file = os.path.join(ROOT_QASYSTEM_PACKAGE,'src/cs_qa_system_torch/information_retrieval/ir_inference.py')\n",
    "\n",
    "%run -i  $python_file \\\n",
    "        --passage_collection_path {ROOT_QASYSTEM_DATA+'InformationRetrievalData/amazon/finetune_passage_collection.json'} \\\n",
    "        --qrels_path {ROOT_QASYSTEM_DATA+'InformationRetrievalData/amazon/finetune_qrels_rank_test.json'} \\\n",
    "        --rank_model_name_or_path 'BM25Okapi' \\\n",
    "        --rank_top_n 20 \\\n",
    "        --do_rerank \\\n",
    "        --rerank_model_name_or_path {ROOT_QASYSTEM_ARTIFACTS+'ir_artifacts/biencoder_bertbase_hardneg_inference/'}\n",
    "        --rerank_batch_size 256 \\\n",
    "        --rerank_top_n 10 \\\n",
    "        --rerank_threshold_score 0.0 \\\n",
    "        --rerank_score_weight 1.0 \\\n",
    "        --output_dir {ROOT_QASYSTEM_ARTIFACTS+'ir_artifacts/BM25_inference/'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference (BM25 + CrossEncoder) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ROOT_QASYSTEM_PACKAGE = '/home/srikamma/efs/workspace/CS-QASystem-Torch/src/CS-QASystem-Torch/'\n",
    "ROOT_QASYSTEM_DATA = '/data/QAData/'\n",
    "ROOT_QASYSTEM_ARTIFACTS = '/data/QAArtifacts/'\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(ROOT_QASYSTEM_PACKAGE,'src/cs_qa_system_torch/'))\n",
    "\n",
    "python_file = os.path.join(ROOT_QASYSTEM_PACKAGE,'src/cs_qa_system_torch/information_retrieval/ir_inference.py')\n",
    "\n",
    "%run -i $python_file \\\n",
    "        --gpu 0,1 \\\n",
    "        --passage_collection_path '/data/qyouran/QABot/d2_benchmark/final_data/passage_collection_expanded.json' \\\n",
    "        --qrels_path '/data/qyouran/QABot/d2_benchmark/final_data/qrels.json' \\\n",
    "        --rank_model_name_or_path 'BM25Okapi' \\\n",
    "        --rank_top_n 100 \\\n",
    "        --rank_threshold_score -1.0 \\\n",
    "        --do_rerank \\\n",
    "        --rerank_model_name_or_path '/data/qyouran/QABot/output_torch_train/d2_benchmark_cross_from_scratch/' \\\n",
    "        --rerank_batch_size 512 \\\n",
    "        --rerank_top_n 10 \\\n",
    "        --rerank_threshold_score -1.0 \\\n",
    "        --rerank_score_weight 0.65 \\\n",
    "        --prediction_file 'prediction.tsv' \\\n",
    "        --output_dir {ROOT_QASYSTEM_ARTIFACTS+'ir_artifacts/BM25_inference/'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real Time Inference for Ranking Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_QASYSTEM_PACKAGE = '/home/srikamma/efs/workspace/CS-QASystem-Torch/src/CS-QASystem-Torch/'\n",
    "ROOT_QASYSTEM_DATA = '/data/QAData/'\n",
    "ROOT_QASYSTEM_ARTIFACTS = '/data/QAArtifacts/'\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(ROOT_QASYSTEM_PACKAGE,'src/cs_qa_system_torch/'))\n",
    "\n",
    "from information_retrieval.ir_inference_realtime import RankPrediction\n",
    "df = RankPrediction.get_documents([(1,'recharge'), (2,'cancel my order')])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ROOT_QASYSTEM_PACKAGE = '/home/srikamma/efs/workspace/CS-QASystem-Torch/src/CS-QASystem-Torch/'\n",
    "ROOT_QASYSTEM_DATA = '/data/QAData/'\n",
    "ROOT_QASYSTEM_ARTIFACTS = '/data/QAArtifacts/'\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(ROOT_QASYSTEM_PACKAGE,'src/cs_qa_system_torch/'))\n",
    "\n",
    "from information_retrieval.ir_inference_realtime import RankPrediction\n",
    "\n",
    "RankPrediction.passage_collection_path = '/data/qyouran/QABot/d2_benchmark/final_data/passage_collection_expanded.json'\n",
    "RankPrediction.rank_top_n = 10\n",
    "RankPrediction.rank_model_score_threshold = -1.0\n",
    "RankPrediction.rank_model_name_or_path = '/home/yqinamz/output/ir_artifacts/biencoder_bertbase_inBatchNeg8/'\n",
    "RankPrediction.do_rerank = False\n",
    "\n",
    "\n",
    "df = RankPrediction.get_documents('troubleshoot kindle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ROOT_QASYSTEM_PACKAGE = '/home/srikamma/efs/workspace/CS-QASystem-Torch/src/CS-QASystem-Torch/'\n",
    "ROOT_QASYSTEM_DATA = '/data/QAData/'\n",
    "ROOT_QASYSTEM_ARTIFACTS = '/data/QAArtifacts/'\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(ROOT_QASYSTEM_PACKAGE,'src/cs_qa_system_torch/'))\n",
    "\n",
    "from information_retrieval.ir_inference_realtime import RankPrediction\n",
    "\n",
    "RankPrediction.passage_collection_path = '/data/qyouran/QABot/d2_benchmark/final_data/passage_collection_expanded.json'\n",
    "RankPrediction.rank_top_n = 100\n",
    "RankPrediction.rank_model_score_threshold = -1.0\n",
    "RankPrediction.rerank_model_name_or_path = '/data/qyouran/QABot/output_torch_train/d2_benchmark_cross_from_scratch/'\n",
    "RankPrediction.rerank_top_n = 10\n",
    "RankPrediction.do_rerank = True\n",
    "RankPrediction.rerank_model_score_threshold = -1.0\n",
    "RankPrediction.rerank_weight_for_mixed_score = 0.65\n",
    "\n",
    "df = RankPrediction.get_documents('alexa')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
