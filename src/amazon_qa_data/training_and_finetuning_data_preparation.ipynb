{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/data/qyouran/QABot/CS-QASystem/src/CS-QASystem/src/cs_qa_system/')\n",
    "sys.path.append('/data/qyouran/QABot/CS-QASystem/src/CS-QASystem/src/ms_marco/')\n",
    "sys.path.append('/data/qyouran/QABot/CS-QASystem/src/CS-QASystem/src/amazon_qa_data/')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "from json import JSONDecodeError\n",
    "from tqdm import tqdm\n",
    "from factory.word_tokenizer_factory import english_preprocessor\n",
    "from data_preparation import download_from_s3, get_files_in_folder, get_idx_collection\n",
    "\n",
    "def is_sorted(x, ascending=True):\n",
    "    if ascending:\n",
    "        return all(x[i] <= x[i + 1] for i in range(len(x) - 1))\n",
    "    else:\n",
    "        return all(x[i] >= x[i + 1] for i in range(len(x) - 1))\n",
    "    \n",
    "def is_1_to_1(x, y):\n",
    "    assert len(x) == len(y)\n",
    "    d = dict()\n",
    "    for i in tqdm(range(len(x))):\n",
    "        if x[i] not in d:\n",
    "            if y[i] in set(d.values()):\n",
    "                return False\n",
    "            d[x[i]] = y[i]\n",
    "        else:\n",
    "            if d[x[i]] != y[i]:\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get MSMARCO data (preprocessed) and Amazon data (preprocessed & unified) for IR model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get preprocessed MS train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_ms_data_path = '/data/qyouran/QABot/QAData/MSMARCO/50000_1_4-preprocessed'\n",
    "os.makedirs(preprocessed_ms_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ms_train = pd.read_csv('/data/QAData/MSMARCO/50000_1_4/train.tsv', sep='\\t', index_col=False)\n",
    "ms_train, ms_train_query_preprocessed_col = english_preprocessor.preprocess(ms_train, 'query')\n",
    "ms_train, ms_train_passage_preprocessed_col = english_preprocessor.preprocess(ms_train, 'passage')\n",
    "ms_train = ms_train.drop(columns=['query', 'passage']).rename(columns={ms_train_query_preprocessed_col: 'query', ms_train_passage_preprocessed_col: 'passage'})\n",
    "ms_train.to_csv(os.path.join(preprocessed_ms_data_path, 'train-preprocessed.tsv'), sep='\\t', index=False)\n",
    "ms_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ms_test = pd.read_csv('/data/QAData/MSMARCO/50000_1_4/test.tsv', sep='\\t', index_col=False)\n",
    "ms_test, ms_test_query_preprocessed_col = english_preprocessor.preprocess(ms_test, 'query')\n",
    "ms_test, ms_test_passage_preprocessed_col = english_preprocessor.preprocess(ms_test, 'passage')\n",
    "ms_test = ms_test.drop(columns=['query', 'passage']).rename(columns={ms_test_query_preprocessed_col: 'query', ms_test_passage_preprocessed_col: 'passage'})\n",
    "ms_test.to_csv(os.path.join(preprocessed_ms_data_path, 'test-preprocessed.tsv'), sep='\\t', index=False)\n",
    "ms_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get preprocessed and unified Amazon train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The following command generates data_all, rank_train, rank_test, query_collection, passage_collection\n",
    "# The codes to generate answer_train and answer_test are retained in data_preparation.py, but are skipped and never used in practice\n",
    "\n",
    "%run -i /data/qyouran/QABot/CS-QASystem/src/CS-QASystem/src/amazon_qa_data/data_preparation.py \\\n",
    "        --root_path '/data/qyouran/QABot/QAData/AmazonQAData/Data-500-4.0-(445,np.inf)-original-None-unified_passage' \\\n",
    "        --data_path '/data/qyouran/QABot/QAData/AmazonQAData/qabot-annotation-output' \\\n",
    "        --data_new_path '/data/qyouran/QABot/QAData/AmazonQAData/qabot-annotation-output-new' \\\n",
    "        --n_test 500 \\\n",
    "        --r_neg_pos 4 \\\n",
    "        --split_granularity '(445,np.inf)' \\\n",
    "        --text_type 'unified_passage'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split rank_train into training and testing sets, and merge them with ms_train and ms_test respectively to get the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_train = pd.read_csv('/data/qyouran/QABot/QAData/MSMARCO/50000_1_4-preprocessed/train-preprocessed.tsv', sep='\\t', index_col=False)\n",
    "ms_test = pd.read_csv('/data/qyouran/QABot/QAData/MSMARCO/50000_1_4-preprocessed/test-preprocessed.tsv', sep='\\t', index_col=False)\n",
    "amazon_train_test = pd.read_json('/data/qyouran/QABot/QAData/AmazonQAData/Data-500-4.0-(445,np.inf)-original-None-unified_passage/rank_train-500-4.0-(445,np.inf)-original-None-unified_passage.json', orient='columns', typ='frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.1\n",
    "resampling_ratio = 5\n",
    "\n",
    "np.random.seed(0)\n",
    "test_query = amazon_train_test['query'].unique()\n",
    "test_query_sampled = np.random.choice(test_query, size=int(test_ratio * test_query.shape[0]), replace=False)\n",
    "test_mask = amazon_train_test['query'].isin(test_query_sampled)\n",
    "\n",
    "amazon_test = amazon_train_test.loc[test_mask, :].reset_index(drop=True)\n",
    "amazon_train = amazon_train_test.loc[~test_mask, :].reset_index(drop=True)\n",
    "\n",
    "amazon_train = pd.concat([amazon_train] * resampling_ratio, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assert set(ms_train.columns) == set(amazon_train.columns)\n",
    "train = ms_train.append(amazon_train, ignore_index=True, sort=True).sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assert set(ms_test.columns) == set(amazon_test.columns)\n",
    "test = ms_test.append(amazon_test, ignore_index=True, sort=True).sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get passages returned by BM25, and use these passages to get the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i /data/qyouran/QABot/CS-QASystem/src/CS-QASystem/src/cs_qa_system/ir_inference.py \\\n",
    "        --passage_collection_path '/data/qyouran/QABot/QAData/AmazonQAData/Data-500-4.0-(445,np.inf)-original-None-unified_passage/passage_collection-500-4.0-(445,np.inf)-original-None-unified_passage.json' \\\n",
    "        --qrels_path '/data/qyouran/QABot/QAData/AmazonQAData/Data-500-4.0-(445,np.inf)-original-None-unified_passage/rank_test-500-4.0-(445,np.inf)-original-None-unified_passage.json' \\\n",
    "        --result_dir '/data/qyouran/QABot/QAData/AmazonQAData/Data-500-4.0-(445,np.inf)-original-None-unified_passage/BM25' \\\n",
    "        --ir_model_name 'BM25Okapi-500-4.0-(445,np.inf)-original-None-unified_passage' \\\n",
    "        --word_tokenizer_name 'simple_word_tokenizer_no_stopwords_stem' \\\n",
    "        --n 100 \\\n",
    "        --add_preprocessed 1 \\\n",
    "        --all_k '1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100' \\\n",
    "        --all_rank_thres_interested '1,2,3,4,5,6,7,8,9,10,20,30,40,50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid = pd.read_csv('/data/qyouran/QABot/QAData/AmazonQAData/Data-500-4.0-(445,np.inf)-original-None-unified_passage/BM25/BM25Okapi-500-4.0-(445,np.inf)-original-None-unified_passage_prediction.tsv', sep='\\t', index_col=False)\n",
    "valid = valid.reindex(columns=['qid', 'query', 'pid', 'passage', 'label'])\n",
    "print(valid['label'].value_counts())\n",
    "valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the training, testing and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_path = '/data/qyouran/QABot/QAData/MSAmazonFinalData_PreprocessedUnified'\n",
    "os.makedirs(final_data_path)\n",
    "\n",
    "train.to_csv(os.path.join(final_data_path, 'train.tsv'), sep='\\t', index=False)\n",
    "test.to_csv(os.path.join(final_data_path, 'test.tsv'), sep='\\t', index=False)\n",
    "valid.to_csv(os.path.join(final_data_path, 'valid.tsv'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Amazon data (augmented by QSM) for IR and AE model finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the annotated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to change \"aws_access_key_id\" and \"aws_secret_access_key\" accordingly\n",
    "data_path = download_from_s3(\n",
    "    root_path='/data/qyouran/QABot/QAData/HelpDoc_InitialLaunch/qabot-annotation-output-ir-b', \n",
    "    s3_region='us-east-1', \n",
    "    aws_access_key_id='aws_access_key_id', \n",
    "    aws_secret_access_key='aws_secret_access_key', \n",
    "    bucket_name='qabot-annotation-output-ir-b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = '/data/qyouran/QABot/QAData/HelpDoc_InitialLaunch/qabot-annotation-output-ir-b'\n",
    "all_data_name = get_files_in_folder(data_path, end_with='.txt', not_start_with=('count.txt', ),\n",
    "                                    return_full_path=False, keep_ext=False, recursively=False)\n",
    "all_data = list()\n",
    "all_source_path = list()\n",
    "for data_name in all_data_name:\n",
    "    try:\n",
    "        with open(os.path.join(data_path, data_name + '.txt'), 'r') as f:\n",
    "            all_data.append(json.load(f))\n",
    "            all_source_path.append(os.path.join(os.path.basename(data_path.rstrip('/')), data_name + '.txt'))\n",
    "    except JSONDecodeError:\n",
    "        print('{:}.txt has incorrect format so it is not loaded'.format(data_name))\n",
    "\n",
    "data = pd.DataFrame(all_data).astype({'query': str, 'passage': str, 'label': int, 'answer': str, 'user': str})\n",
    "assert data.notnull().all(axis=None)\n",
    "\n",
    "# We will sort it by filenames such that the passages of each query are sorted by their BM25 relevance scores (the first passage has the highest score)\n",
    "data['source_path'] = all_source_path\n",
    "data['filename_to_sort'] = data['source_path'].map(lambda x: int(x.split('/')[-1][:-4]))\n",
    "data = data.sort_values('filename_to_sort').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def modify_string(data, col, old, new, print_info=False):\n",
    "    s = set()\n",
    "    for i in data.index:\n",
    "        old_string = data.loc[i, col]\n",
    "        new_string = old_string.replace(old, new)\n",
    "        if old_string != new_string:\n",
    "            data.loc[i, col] = new_string\n",
    "            if (old_string not in s) and print_info:\n",
    "                print('    {0:}\\n -> {1:}'.format(old_string, new_string))\n",
    "            s.add(old_string)\n",
    "    print('{0:d} unique {1:} are modified ({2:} -> {3:})\\n'.format(len(s), col, old, new))\n",
    "    \n",
    "modify_string(data, 'query', '&nbsp;', '\\xa0', print_info=True)\n",
    "modify_string(data, 'query', '&amp;', '&', print_info=True)\n",
    "\n",
    "modify_string(data, 'passage', '&nbsp;', '\\xa0', print_info=True)\n",
    "modify_string(data, 'passage', '&amp;', '&', print_info=False)\n",
    "\n",
    "modify_string(data, 'answer', '&nbsp;', '\\xa0', print_info=True)\n",
    "modify_string(data, 'answer', '&amp;', '&', print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query has an answer but its \"label\" was incorrectly labeled as 0, so I change it to 1\n",
    "wrong_labels_index = [4120]\n",
    "for i in wrong_labels_index:\n",
    "    data.loc[i, 'label'] = 1\n",
    "\n",
    "duplicated_queries = [\"I'd like to add an item to my existing order\", \"An item received as a gift\", \"Return item help\"]\n",
    "index_removed = list()\n",
    "for query in duplicated_queries:\n",
    "    temp = data.loc[data['query'] == query, ['query', 'passage', 'label', 'answer', 'user']]\n",
    "    index_removed.extend(list(temp.iloc[10:, :].index))\n",
    "    assert (temp.iloc[:10, :].reset_index(drop=True) == temp.iloc[10:, :].reset_index(drop=True)).all(axis=None)\n",
    "data = data.drop(index=index_removed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_all = pd.read_csv('/data/qyouran/QABot/QAData/HelpDoc_InitialLaunch/all_queries_considered_in_experiment.tsv', sep='\\t', index_col=False)\n",
    "assert df_query_all['qid'].is_unique and df_query_all['query'].is_unique\n",
    "\n",
    "data = pd.merge(left=data, right=df_query_all, on=['query'], how='left', validate='many_to_one', indicator=True)\n",
    "assert (data['_merge'] == 'both').all()\n",
    "data = data.drop(columns=['_merge'])\n",
    "\n",
    "data['base_qid'] = data['qid']\n",
    "data['base_query'] = data['query']\n",
    "data['qs_score'] = 1.0\n",
    "\n",
    "data = data.loc[:, ['base_qid', 'base_query', 'qs_score', 'qid', 'query', 'freq', 'passage', 'label', 'answer', 'user', 'source_path', 'filename_to_sort']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "for i in data.index:\n",
    "    if data.loc[i, 'label'] == 0:\n",
    "        assert data.loc[i, 'answer'] == ''\n",
    "    else:\n",
    "        assert data.loc[i, 'label'] == 1\n",
    "        assert (data.loc[i, 'answer'] != '') and (data.loc[i, 'answer'] in data.loc[i, 'passage'])\n",
    "assert data['query'].nunique() * 10 == data.shape[0]\n",
    "assert (not data.duplicated(['query', 'passage']).any())\n",
    "assert is_sorted(data['filename_to_sort'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Number of queries each user annotated:')\n",
    "print(data['user'].value_counts() // 10)\n",
    "\n",
    "n_covered = data.groupby('query').apply(lambda x: (x['label'] == 1).any()).sum()\n",
    "n = data['query'].nunique()\n",
    "print('{0:d}/{1:d} = {2:.2f}% of queries have >= 1 answers'.format(n_covered, n, 100 * n_covered / n))\n",
    "\n",
    "data.to_csv('/data/qyouran/QABot/QAData/HelpDoc_InitialLaunch/finetune_annotation_result.tsv', sep='\\t', index=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get similar queries for each query we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/data/qyouran/QABot/QAData/HelpDoc_InitialLaunch/finetune_annotation_result.tsv', sep='\\t', index_col=False).fillna('')\n",
    "\n",
    "df_query_all = pd.read_csv('/data/qyouran/QABot/QAData/HelpDoc_InitialLaunch/all_queries_considered_in_experiment.tsv', sep='\\t', index_col=False)\n",
    "assert df_query_all['qid'].is_unique and df_query_all['query'].is_unique\n",
    "\n",
    "similar_queries = dict()\n",
    "with open('/home/yqinamz/QA_Bot/IR/ir_data/850k_similar_top5.json', 'r') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            temp = json.loads(line)\n",
    "        except JSONDecodeError:\n",
    "            print('The format of the following line is wrong, so loading is stopped (there are already {0:d} queries in similar_queries):\\n\\n{1:}'.format(len(similar_queries), line))\n",
    "            break\n",
    "        assert len(temp['similar_q']) == 5\n",
    "        similar_queries[int(temp['qid'])] = max(temp['similar_q'], key=lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l = [v + [qid] for qid, v in similar_queries.items()]\n",
    "\n",
    "df_query_aug = pd.DataFrame(l, columns=['base_qid', 'base_query', 'qs_score', 'qid']).astype({'base_qid': int, 'base_query': str, 'qid': int})\n",
    "assert df_query_aug['qid'].is_unique\n",
    "\n",
    "df_query_aug = df_query_aug.loc[~df_query_aug['base_qid'].isin({75844, 1124315}), :].reset_index(drop=True)\n",
    "\n",
    "df_query_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get back the freq and query\n",
    "df_query_aug = pd.merge(left=df_query_aug, right=df_query_all, on=['qid'], how='left', validate='one_to_one', indicator=True)\n",
    "assert (df_query_aug['_merge'] == 'both').all()\n",
    "df_query_aug = df_query_aug.drop(columns=['_merge'])\n",
    "\n",
    "df_query_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_query_aug['query_deduplicate'] = df_query_aug['query'].str.lower()\n",
    "\n",
    "query_deduplicate_mask = df_query_aug.duplicated(['query_deduplicate'], keep=False)\n",
    "temp = df_query_aug.loc[query_deduplicate_mask, :].groupby('query_deduplicate').apply(lambda x: x.sort_values('qs_score', ascending=False).iloc[0, :]).reset_index(drop=True)\n",
    "df_query_aug = df_query_aug.loc[~query_deduplicate_mask, :].append(temp).reset_index(drop=True)\n",
    "\n",
    "annotated_queries = set(data['query'].to_list())\n",
    "annotated_queries = {s.lower() for s in annotated_queries}\n",
    "annotated_queries_mask = df_query_aug['query_deduplicate'].isin(annotated_queries)\n",
    "assert annotated_queries_mask.sum() == 998\n",
    "df_query_aug = df_query_aug.loc[~annotated_queries_mask, :]\n",
    "\n",
    "df_query_aug = df_query_aug.drop(columns=['query_deduplicate']).reset_index(drop=True)\n",
    "\n",
    "df_query_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retain only the queries with high qs_score \n",
    "similarity_threshold = 0.94\n",
    "df_query_aug = df_query_aug.loc[df_query_aug['qs_score'] > similarity_threshold, :].reset_index(drop=True)\n",
    "df_query_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "assert df_query_aug['query'].str.lower().is_unique and df_query_aug['qid'].is_unique\n",
    "assert is_1_to_1(df_query_aug['qid'].to_list(), df_query_aug['query'].to_list())\n",
    "assert is_1_to_1(df_query_aug['base_qid'].to_list(), df_query_aug['base_query'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the annotations \n",
    "n_original = df_query_aug.shape[0]\n",
    "\n",
    "df_query_aug = pd.merge(left=df_query_aug, right=data.loc[:, ['base_qid', 'base_query', 'passage', 'label', 'answer', 'filename_to_sort']], how='left', on=['base_qid', 'base_query'], indicator=True)\n",
    "assert (df_query_aug['_merge'] == 'both').all()\n",
    "df_query_aug = df_query_aug.drop(columns=['_merge'])\n",
    "\n",
    "assert n_original * 10 == df_query_aug.shape[0]\n",
    "\n",
    "df_query_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_unique_original = df_query_aug['query'].str.lower().nunique()\n",
    "data_columns = list(data.drop(columns=['user', 'source_path']).columns)\n",
    "assert sorted(list(df_query_aug.columns)) == sorted(data_columns)\n",
    "df_query_aug = df_query_aug.reindex(columns=data_columns)\n",
    "df_query_aug = df_query_aug.append(data.drop(columns=['user', 'source_path']), ignore_index=True)\n",
    "assert df_query_aug['query'].str.lower().nunique() - n_unique_original == 998\n",
    "\n",
    "df_query_aug = df_query_aug.sort_values(['qid', 'filename_to_sort'], ascending=[True, True]).reset_index(drop=True)\n",
    "\n",
    "def check(x):\n",
    "    assert x['qs_score'].nunique() == 1\n",
    "    assert x['freq'].nunique() == 1\n",
    "    assert x['base_qid'].nunique() == 1\n",
    "    assert x['base_query'].nunique() == 1\n",
    "df_query_aug.groupby('qid').apply(check)\n",
    "assert is_1_to_1(df_query_aug['qid'].to_list(), df_query_aug['query'].to_list())\n",
    "assert is_1_to_1(df_query_aug['base_qid'].to_list(), df_query_aug['base_query'].to_list())\n",
    "\n",
    "df_query_aug.to_csv('/data/qyouran/QABot/QAData/HelpDoc_InitialLaunch/finetune_data_large/df_query_aug.tsv', sep='\\t', index=False)\n",
    "df_query_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_aug = pd.read_csv('/data/qyouran/QABot/QAData/HelpDoc_InitialLaunch/finetune_data_large/df_query_aug.tsv', sep='\\t', index_col=False).fillna('')\n",
    "assert df_query_aug['query'].nunique() * 10 == df_query_aug.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_query_aug_selected = copy.deepcopy(df_query_aug)\n",
    "df_query_aug_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def adjust_ratio(x, r_neg_to_pos=3):\n",
    "    assert x['label'].isin({0, 1}).all()\n",
    "    assert is_sorted(x['filename_to_sort'].to_list())\n",
    "    \n",
    "    mask_pos = (x['label'] == 1)\n",
    "    n_pos = mask_pos.sum()\n",
    "    n_neg = int(max(r_neg_to_pos, n_pos * r_neg_to_pos))\n",
    "    \n",
    "    df_pos = x.loc[mask_pos, :]\n",
    "    df_neg = x.loc[~mask_pos, :].iloc[:n_neg, :]\n",
    "    \n",
    "    return df_pos.append(df_neg, ignore_index=True)\n",
    "\n",
    "df_query_aug_selected_ratio = df_query_aug_selected.groupby('query').apply(adjust_ratio).reset_index(drop=True)\n",
    "df_query_aug_selected_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get preprocessed passages\n",
    "english_preprocessor.noise_regex['URL'] = (re.compile(r'(\\(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^)\\s]{2,}|www\\.[a-zA-Z0-9]' \\\n",
    "                                                      r'[a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^)\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^)\\s]{2,}|www\\.' \\\n",
    "                                                      r'[a-zA-Z0-9]+\\.[^)\\s]{2,})'), )\n",
    "\n",
    "df_query_aug_selected_ratio['passage_preprocessed'] = df_query_aug_selected_ratio['passage'].map(english_preprocessor.preprocess_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pid and passage collection\n",
    "passage_id, _ = get_idx_collection(df_query_aug_selected_ratio['passage'].to_list(), dict())\n",
    "df_query_aug_selected_ratio['pid'] = passage_id\n",
    "df_query_aug_selected_ratio = df_query_aug_selected_ratio.loc[:, ['base_qid', 'base_query', 'qs_score', 'qid', 'query', 'freq', 'pid', 'passage', 'passage_preprocessed', 'label', 'answer', 'filename_to_sort']]\n",
    "\n",
    "assert is_1_to_1(df_query_aug_selected_ratio['pid'].to_list(), df_query_aug_selected_ratio['passage'].to_list())\n",
    "assert is_1_to_1(df_query_aug_selected_ratio['pid'].to_list(), df_query_aug_selected_ratio['passage_preprocessed'].to_list())\n",
    "\n",
    "passage_collection = dict()\n",
    "for i in tqdm(df_query_aug_selected_ratio.index):\n",
    "    pid = int(df_query_aug_selected_ratio.loc[i, 'pid'])\n",
    "    if pid not in passage_collection:\n",
    "        passage_collection[pid] = [df_query_aug_selected_ratio.loc[i, 'passage'], df_query_aug_selected_ratio.loc[i, 'passage_preprocessed']]\n",
    "with open('/data/qyouran/QABot/QAData/HelpDoc_InitialLaunch/finetune_data_large/finetune_passage_collection.json', 'w') as f:\n",
    "    json.dump(passage_collection, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_covered = df_query_aug_selected_ratio.groupby('query').apply(lambda x: (x['label'] == 1).any()).sum()\n",
    "n = df_query_aug_selected_ratio['query'].nunique()\n",
    "print('In the augmented data, {0:d}/{1:d} = {2:.2f}% of queries have >= 1 answers'.format(n_covered, n, 100 * n_covered / n))\n",
    "\n",
    "print(df_query_aug_selected_ratio['label'].value_counts())\n",
    "\n",
    "df_query_aug_selected_ratio.to_csv('/data/qyouran/QABot/QAData/HelpDoc_InitialLaunch/finetune_data_large/df_query_aug_selected_ratio.tsv', sep='\\t', index=False)\n",
    "df_query_aug_selected_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the final training and testing datasets for IR and AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_aug_selected_ratio = pd.read_csv('/data/qyouran/QABot/QAData/HelpDoc_InitialLaunch/finetune_data_large/df_query_aug_selected_ratio.tsv', sep='\\t', index_col=False).fillna('')\n",
    "\n",
    "with open('/data/qyouran/QABot/QAData/HelpDoc_InitialLaunch/finetune_data_small/test_qid_sampled_small', 'rb') as f:\n",
    "    test_qid_sampled_small = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "test_qid = df_query_aug_selected_ratio['qid'].unique()\n",
    "test_qid_sampled = np.random.choice(test_qid, size=int(test_qid.shape[0] * 0.1), replace=False)\n",
    "test_qid_sampled = set(test_qid_sampled) | set(test_qid_sampled_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_data = copy.deepcopy(df_query_aug_selected_ratio.loc[:, ['qid', 'query', 'pid', 'passage_preprocessed', 'label']].rename(columns={'passage_preprocessed': 'passage'}))\n",
    "\n",
    "rank_data = rank_data.sort_values(['qid', 'label'], ascending=[True, False])\n",
    "\n",
    "mask_rank_test = rank_data['qid'].isin(test_qid_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rank_test = rank_data.loc[mask_rank_test, :].reset_index(drop=True)\n",
    "\n",
    "n_covered = rank_test.groupby('query').apply(lambda x: (x['label'] == 1).any()).sum()\n",
    "n = rank_test['query'].nunique()\n",
    "print('In rank_test, {0:d}/{1:d} = {2:.2f}% of queries have >= 1 answers'.format(n_covered, n, 100 * n_covered / n))\n",
    "\n",
    "print(rank_test['label'].value_counts())\n",
    "\n",
    "rank_test.to_csv('/data/qyouran/QABot/QAData/HelpDoc_InitialLaunch/finetune_data_large/finetune_rank_test.tsv', sep='\\t', index=False)\n",
    "rank_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rank_train = rank_data.loc[~mask_rank_test, :].reset_index(drop=True)\n",
    "\n",
    "n_covered = rank_train.groupby('query').apply(lambda x: (x['label'] == 1).any()).sum()\n",
    "n = rank_train['query'].nunique()\n",
    "print('In rank_train, {0:d}/{1:d} = {2:.2f}% of queries have >= 1 answers'.format(n_covered, n, 100 * n_covered / n))\n",
    "\n",
    "print(rank_train['label'].value_counts())\n",
    "\n",
    "rank_train.to_csv('/data/qyouran/QABot/QAData/HelpDoc_InitialLaunch/finetune_data_large/finetune_rank_train.tsv', sep='\\t', index=False)\n",
    "rank_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_data = copy.deepcopy(df_query_aug_selected_ratio.loc[df_query_aug_selected_ratio['label'] == 1, ['qid', 'query', 'passage', 'answer']])\n",
    "\n",
    "assert answer_data.apply(lambda x: (x['answer'] != '') and (x['answer'] in x['passage']), axis=1).all()\n",
    "\n",
    "answer_data['query_deduplicate'] = answer_data['query'].str.lower()\n",
    "assert not answer_data.duplicated(['query_deduplicate', 'passage']).any()\n",
    "answer_data = answer_data.drop(columns='query_deduplicate')\n",
    "\n",
    "answer_data = answer_data.sort_values('qid', ascending=True)\n",
    "\n",
    "mask_answer_test = answer_data['qid'].isin(test_qid_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "answer_test = answer_data.loc[mask_answer_test, :].reset_index(drop=True)\n",
    "\n",
    "answer_test.to_csv('/data/qyouran/QABot/QAData/HelpDoc_InitialLaunch/finetune_data_large/finetune_answer_test.tsv', sep='\\t', index=False)\n",
    "answer_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "answer_train = answer_data.loc[~mask_answer_test, :].reset_index(drop=True)\n",
    "\n",
    "answer_train.to_csv('/data/qyouran/QABot/QAData/HelpDoc_InitialLaunch/finetune_data_large/finetune_answer_train.tsv', sep='\\t', index=False)\n",
    "answer_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qabot",
   "language": "python",
   "name": "qabot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
